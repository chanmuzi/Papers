[Stnaford, Toronto] Observational Scaling Laws and the Predictability of Language Model Performance

# Points
- Abstract
  - 80개의 publically available models를 바탕으로 'observational approach'를 제안하여 모델 학습을 하지 않으면서도 scaling law를 추정 가능하도록 함
  - 이때 low-dimensional capability space를 활용. metric에서 PC (principal capability) 라는 개념을 활용
    
    <img width="350" alt="image" src="https://github.com/chanmuzi/Papers/assets/101971295/d690e4ae-2552-4441-bbee-735b2847ab9b">

- 관련 연구
  - Compute scaling laws
  - Downstream scaling laws
  - Correlations between benchmarks
- scaling에 관한 자세한 수식은 논문 참고
- 평가: 작은 사이즈 모델들의 평가 결과를 바탕으로 scale-up 예측이 들어맞았다는 것이 포인트
  1. Emergent capabilities of LM 예측
     
     <img width="700" alt="image" src="https://github.com/chanmuzi/Papers/assets/101971295/915a5054-d8a2-41a5-92ad-5ec037fef04e">

  2. Agentic Capabilities 예측

    <img width="700" alt="image" src="https://github.com/chanmuzi/Papers/assets/101971295/ef45f391-52dd-4e25-b367-9b32c328a85e">


  3. Post-Training Impact 예측
     
     <img width="700" alt="image" src="https://github.com/chanmuzi/Papers/assets/101971295/d3874e6f-c764-43c4-be09-074be31e9092">


---
링크: https://arxiv.org/abs/2405.10938
