# Reasoning

|Date|Title(arxiv)|Keyword|Affiliation|Note|
|:---:|:---:|:---:|:---:|:---:|
|2024.01|[LLMs cannot find reasoning errors, but can correct them!](https://arxiv.org/abs/2311.08516)|CoT|Google Research|[short](https://github.com/chanmuzi/Papers/blob/main/Reasoning/LLMs%20cannot%20find%20reasoning%20errors%2C%20but%20can%20correct%20them!.md)|

---
# RAG (Retrieval Augmented Generation)
|Date|Title(arxiv)|Keyword|Affiliation|Note|
|:---:|:---:|:---:|:---:|:---:|
|2023.02|[Augmented Language Models: a Survey](https://arxiv.org/abs/2302.07842)|RAG, Survey|Meta|[short](https://github.com/chanmuzi/Papers/blob/main/RAG/Augmented%20Language%20Models%3A%20a%20Survey.md)|
|2023.10|[Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!](https://arxiv.org/abs/2303.08559)|Rerank|Nanyang Technological University|[short]|

---
# Training
|Date|Title(arxiv)|Keyword|Affiliation|Note|
|:---:|:---:|:---:|:---:|:---:|
|2023.12|[Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision](https://arxiv.org/abs/2312.09390)|superhuman model|OpenAI|[long](https://chanmuzi.tistory.com/469)|
