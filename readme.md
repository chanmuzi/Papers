# Reasoning

|Date|Title(arxiv)|Keyword|Affiliation|Note|
|:---:|:---:|:---:|:---:|:---:|
|2024.01|[LLMs cannot find reasoning errors, but can correct them!](https://arxiv.org/abs/2311.08516)|CoT|Google Research|[Markdown](https://github.com/chanmuzi/Papers/blob/main/Reasoning/LLMs%20cannot%20find%20reasoning%20errors%2C%20but%20can%20correct%20them!.md)|





---
# RAG (Retrieval Augmented Generation)
|Date|Title(arxiv)|Keyword|Affiliation|Note|
|:---:|:---:|:---:|:---:|:---:|
|2023.02|[Augmented Language Models: a Survey](https://arxiv.org/abs/2302.07842)|RAG, Survey|Meta|[Markdown](https://github.com/chanmuzi/Papers/blob/main/RAG/Augmented%20Language%20Models%3A%20a%20Survey.md)|
|2023.10|[Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!](https://arxiv.org/abs/2303.08559)|Reranking|Nanyang Technological University|[Markdown](https://github.com/chanmuzi/Papers/blob/main/RAG/Large%20Language%20Model%20Is%20Not%20a%20Good%20Few-shot%20Information%20Extractor%2C%20but%20a%20Good%20Reranker%20for%20Hard%20Samples!.md)|
|2023.12|[RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!](https://arxiv.org/abs/2312.02724)|Reranking|University of Waterloo|[Markdown](https://github.com/chanmuzi/Papers/blob/main/RAG/RankZephyr:%20Effective%20and%20Robust%20Zero-Shot%20Listwise%20Reranking%20is%20a%20Breeze!.md)|





---
# Training
|Date|Title(arxiv)|Keyword|Affiliation|Note|
|:---:|:---:|:---:|:---:|:---:|
|2023.12|[Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision](https://arxiv.org/abs/2312.09390)|superhuman model|OpenAI|[Blog](https://chanmuzi.tistory.com/469)|
|2024.01|[Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://arxiv.org/abs/2401.01335)|Self-Play||[Markdown](https://github.com/chanmuzi/Papers/blob/main/Training/Self-Play%20Fine-Tuning%20Converts%20Weak%20Language%20Models%20to%20Strong%20Language%20Models.md)|
|2024.01|[Knowledge Fusion of Large Language Models](https://arxiv.org/abs/2401.10491)|Knowledge Fusion|Tencent AI Lan|[Blog](https://chanmuzi.tistory.com/470)|


---
# Prompting
|Date|Title(arxiv)|Keyword|Affiliation|Note|
|:---:|:---:|:---:|:---:|:---:|
|2024.01|[Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding](https://arxiv.org/abs/2401.12954)|Meta-Prompting|Stanford University, OpenAI|[Markdown](https://github.com/chanmuzi/Papers/blob/main/Prompting/Meta-Prompting%3A%20Enhancing%20Language%20Models%20with%20Task-Agnostic%20Scaffolding.md)|
